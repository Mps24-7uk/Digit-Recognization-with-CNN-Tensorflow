{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"Digit recognizer/train.csv\")\n",
    "test=pd.read_csv(\"Digit recognizer/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Out the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3c9d96dcc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBEX4gaAIPxAU4QeC+l/WC645+dyeaQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3c9d1b88d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = train.loc[1][1:].values.reshape((28,28))\n",
    "plt.imshow(img, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next_batch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes 100 Rows(pixel)per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_num = 0\n",
    "examples_num = train.shape[0]\n",
    "def next_batch(batch_size):\n",
    "    global batch_num\n",
    "    global train\n",
    "\n",
    "    start = batch_num\n",
    "    end = batch_num + batch_size - 1\n",
    "\n",
    "    if end > examples_num:\n",
    "        train = train.sample(frac=1).reset_index(drop=True)\n",
    "        batch_num = 0\n",
    "        start = batch_num\n",
    "        end = batch_num + batch_size - 1\n",
    "\n",
    "    data = train.loc[start:end]\n",
    "    labels = data.pop('label')\n",
    "    batch_num = end + 1\n",
    "    return data.values, handle_labels(labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_labels(num_array):\n",
    "    length = len(num_array)\n",
    "    patten = np.zeros([length, 10])\n",
    "    for i in range(length):\n",
    "        patten[i][num_array[i]] = 1\n",
    "    return patten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to help intialize random weights for fully connected or convolutional layers, we leave the shape attribute as a parameter for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as init_weights, but for the biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 2D convolution using builtin conv2d from TF:\n",
    "\n",
    "Computes a 2-D convolution given 4-D input and filter tensors.\n",
    "\n",
    "Given an input tensor of shape [batch, in_height, in_width, in_channels] and a filter / kernel tensor of shape \n",
    "[filter_height, filter_width, in_channels, out_channels], this op performs the following:\n",
    "\n",
    "1. Flattens the filter to a 2-D matrix with shape [filter_height * filter_width * in_channels, output_channels].\n",
    "2. Extracts image patches from the input tensor to form a virtual tensor of shape [batch, out_height, out_width,\n",
    "   filter_height * filter_width * in_channels].\n",
    "3. For each patch, right-multiplies the filter matrix and the image patch vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a max pooling layer, again using built in TF functions:\n",
    "Performs the max pooling on the input.\n",
    "Args:\n",
    "  value: A 4-D `Tensor` with shape `[batch, height, width, channels]` and\n",
    "    type `tf.float32`.\n",
    "  ksize: A list of ints that has length >= 4.  The size of the window for\n",
    "    each dimension of the input tensor.\n",
    "  strides: A list of ints that has length >= 4.  The stride of the sliding\n",
    "    window for each dimension of the input tensor.\n",
    "  padding: A string, either `'VALID'` or `'SAME'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the conv2d function, we'll return an actual convolutional layer here that uses an ReLu activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a normal fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,784])\n",
    "y_true = tf.placeholder(tf.float32,shape=[None,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using a 6by6 filter here, \n",
    "# You can change the 32 output, that essentially represents the amount of filters used\n",
    "# You need to pass in 32 to the next input though, the 1 comes from the original input of  a single image.\n",
    "convo_1 = convolutional_layer(x_image,shape=[6,6,1,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using a 6by6 filter here\n",
    "# You can actually change the 64 output if you want, you can think of that as a representation \n",
    "#of the amount of 6by6 filters used.\n",
    "\n",
    "convo_2 = convolutional_layer(convo_1_pooling,shape=[6,6,32,64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Why 7 by 7 image? Because we did 2 pooling layers, so (28/2)/2 = 7\n",
    "# 64 then just comes from the output of the previous Convolution\n",
    "convo_2_flat = tf.reshape(convo_2_pooling,[-1,7*7*64])\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE THE PLACEHOLDER HERE!\n",
    "hold_prob = tf.placeholder(tf.float32)\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step =  tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saves variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on step 0\n",
      "Accuracy is:\n",
      "0.2\n",
      "\n",
      "\n",
      "Currently on step 100\n",
      "Accuracy is:\n",
      "0.95\n",
      "\n",
      "\n",
      "Currently on step 200\n",
      "Accuracy is:\n",
      "0.9\n",
      "\n",
      "\n",
      "Currently on step 300\n",
      "Accuracy is:\n",
      "0.93\n",
      "\n",
      "\n",
      "Currently on step 400\n",
      "Accuracy is:\n",
      "0.91\n",
      "\n",
      "\n",
      "Currently on step 500\n",
      "Accuracy is:\n",
      "0.93\n",
      "\n",
      "\n",
      "Currently on step 600\n",
      "Accuracy is:\n",
      "0.93\n",
      "\n",
      "\n",
      "Currently on step 700\n",
      "Accuracy is:\n",
      "0.95\n",
      "\n",
      "\n",
      "Currently on step 800\n",
      "Accuracy is:\n",
      "0.92\n",
      "\n",
      "\n",
      "Currently on step 900\n",
      "Accuracy is:\n",
      "0.95\n",
      "\n",
      "\n",
      "Currently on step 1000\n",
      "Accuracy is:\n",
      "0.95\n",
      "\n",
      "\n",
      "Currently on step 1100\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 1200\n",
      "Accuracy is:\n",
      "0.95\n",
      "\n",
      "\n",
      "Currently on step 1300\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 1400\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 1500\n",
      "Accuracy is:\n",
      "0.96\n",
      "\n",
      "\n",
      "Currently on step 1600\n",
      "Accuracy is:\n",
      "0.96\n",
      "\n",
      "\n",
      "Currently on step 1700\n",
      "Accuracy is:\n",
      "0.97\n",
      "\n",
      "\n",
      "Currently on step 1800\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 1900\n",
      "Accuracy is:\n",
      "0.95\n",
      "\n",
      "\n",
      "Currently on step 2000\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 2100\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 2200\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 2300\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 2400\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 2500\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 2600\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 2700\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 2800\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 2900\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 3000\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 3100\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 3200\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 3300\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 3400\n",
      "Accuracy is:\n",
      "0.96\n",
      "\n",
      "\n",
      "Currently on step 3500\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 3600\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 3700\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 3800\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 3900\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 4000\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 4100\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 4200\n",
      "Accuracy is:\n",
      "0.96\n",
      "\n",
      "\n",
      "Currently on step 4300\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 4400\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 4500\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 4600\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 4700\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 4800\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 4900\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 5000\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 5100\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 5200\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 5300\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 5400\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 5500\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 5600\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 5700\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 5800\n",
      "Accuracy is:\n",
      "0.97\n",
      "\n",
      "\n",
      "Currently on step 5900\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 6000\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 6100\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 6200\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 6300\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 6400\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 6500\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 6600\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 6700\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 6800\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 6900\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 7000\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 7100\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 7200\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 7300\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 7400\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 7500\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 7600\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 7700\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 7800\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 7900\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 8000\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 8100\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 8200\n",
      "Accuracy is:\n",
      "0.98\n",
      "\n",
      "\n",
      "Currently on step 8300\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 8400\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 8500\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 8600\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 8700\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 8800\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 8900\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 9000\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 9100\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 9200\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 9300\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 9400\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 9500\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 9600\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 9700\n",
      "Accuracy is:\n",
      "0.99\n",
      "\n",
      "\n",
      "Currently on step 9800\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Currently on step 9900\n",
      "Accuracy is:\n",
      "1.0\n",
      "\n",
      "\n",
      "Model saved in file: model/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "steps = 10000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        \n",
    "        batch_x , batch_y = next_batch(100)\n",
    "        \n",
    "        sess.run(train_step,feed_dict={x:batch_x,y_true:batch_y,hold_prob:0.5})\n",
    "        \n",
    "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "        if i%100 == 0:\n",
    "            \n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is:')\n",
    "            # Test the Train Model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "           # print('step %d, training accuracy %g' % (i, sess.run(acc,feed_dict={x:batch_x,y_true:batch_y,hold_prob:1})))\n",
    "            print(sess.run(acc,feed_dict={x:batch_x,y_true:batch_y,hold_prob:1}))\n",
    "            print('\\n')\n",
    "            \n",
    "    \n",
    "    save_path = saver.save(sess, \"model/model.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed The Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "predicted_lables = np.zeros(test.shape[0])\n",
    "\n",
    "predict = tf.argmax(y_pred, 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  # Restore variables\n",
    "    saver.restore(sess, \"model/model.ckpt\")\n",
    "  # Check the values of the variables\n",
    "    for i in range(0, test.shape[0]//100):\n",
    "        predicted_lables[i*100 : (i+1)*100] = predict.eval(feed_dict={x: test.values[i*100 : (i+1)*100], hold_prob: 1.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displays the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(num='astronaut',figsize=(28,28))\n",
    "for i in range(0,10):  \n",
    "    plt.subplot(1,10,i + 1)\n",
    "    img = test.values[i].reshape((28,28))   \n",
    "    plt.imshow(img, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saves the File in Csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('result.csv', \n",
    "           np.c_[range(1,len(test)+1), predicted_lables], \n",
    "           delimiter=',', \n",
    "           header = 'ImageId,Label', \n",
    "           comments = '',\n",
    "           newline='\\r\\n',\n",
    "           fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
